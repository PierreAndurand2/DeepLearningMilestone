{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project\n",
    "\n",
    "## Milestone report\n",
    "\n",
    "## Study of the impact on the ratio of labeled to unlabeled data on top-1 accuracy on the MNIST dataset\n",
    "\n",
    "Pierre Andurand (pa2570)\n",
    "Tzu Yi Chuang (tc3075)\n",
    "Kuan Yu Ko (kk3376)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part is not needed for now\n",
    "\n",
    "# Import standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import TF layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "# Import TF utilities\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Import TF pretrained models\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.nasnet import NASNetMobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we train a simple model in supervised learning without data augmentation. We check its performance on the mnist dataset. It will be our un-noised teacher model. And we will compare its performance with 100 epochs to the semi supervised self-learning model in the following block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Not using data augmentation.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 2.0303 - accuracy: 0.4059 - val_loss: 1.2557 - val_accuracy: 0.7395\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.8239 - accuracy: 0.7637 - val_loss: 0.5211 - val_accuracy: 0.8427\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.5391 - accuracy: 0.8336 - val_loss: 0.3956 - val_accuracy: 0.8853\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.4334 - accuracy: 0.8669 - val_loss: 0.3262 - val_accuracy: 0.8991\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 59s 1ms/step - loss: 0.3500 - accuracy: 0.8931 - val_loss: 0.2621 - val_accuracy: 0.9237\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 59s 1ms/step - loss: 0.2837 - accuracy: 0.9118 - val_loss: 0.2061 - val_accuracy: 0.9391\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.2353 - accuracy: 0.9276 - val_loss: 0.1699 - val_accuracy: 0.9531\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 59s 1ms/step - loss: 0.1954 - accuracy: 0.9405 - val_loss: 0.1433 - val_accuracy: 0.9583\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.1658 - accuracy: 0.9486 - val_loss: 0.1253 - val_accuracy: 0.9634\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.1450 - accuracy: 0.9557 - val_loss: 0.1089 - val_accuracy: 0.9680\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.1284 - accuracy: 0.9603 - val_loss: 0.1010 - val_accuracy: 0.9696\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.1158 - accuracy: 0.9635 - val_loss: 0.0892 - val_accuracy: 0.9735\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.1066 - accuracy: 0.9674 - val_loss: 0.0858 - val_accuracy: 0.9747\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0970 - accuracy: 0.9691 - val_loss: 0.0801 - val_accuracy: 0.9766\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0902 - accuracy: 0.9720 - val_loss: 0.0728 - val_accuracy: 0.9781\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0831 - accuracy: 0.9743 - val_loss: 0.0699 - val_accuracy: 0.9790\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0764 - accuracy: 0.9759 - val_loss: 0.0671 - val_accuracy: 0.9810\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0737 - accuracy: 0.9773 - val_loss: 0.0640 - val_accuracy: 0.9813\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0698 - accuracy: 0.9781 - val_loss: 0.0609 - val_accuracy: 0.9827\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0648 - accuracy: 0.9801 - val_loss: 0.0604 - val_accuracy: 0.9827\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0623 - accuracy: 0.9804 - val_loss: 0.0568 - val_accuracy: 0.9833\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0602 - accuracy: 0.9814 - val_loss: 0.0562 - val_accuracy: 0.9852\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.0540 - val_accuracy: 0.9857\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0541 - accuracy: 0.9837 - val_loss: 0.0523 - val_accuracy: 0.9861\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.0536 - val_accuracy: 0.9854\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0477 - accuracy: 0.9850 - val_loss: 0.0490 - val_accuracy: 0.9866\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0471 - accuracy: 0.9856 - val_loss: 0.0487 - val_accuracy: 0.9868\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 0.0486 - val_accuracy: 0.9876\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.0432 - accuracy: 0.9863 - val_loss: 0.0490 - val_accuracy: 0.9862\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 0.0467 - val_accuracy: 0.9872\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 0.0479 - val_accuracy: 0.9877\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.0464 - val_accuracy: 0.9868\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0357 - accuracy: 0.9885 - val_loss: 0.0453 - val_accuracy: 0.9883\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 63s 1ms/step - loss: 0.0363 - accuracy: 0.9886 - val_loss: 0.0435 - val_accuracy: 0.9887\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0345 - accuracy: 0.9891 - val_loss: 0.0435 - val_accuracy: 0.9881\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0333 - accuracy: 0.9894 - val_loss: 0.0424 - val_accuracy: 0.9885\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 0.0436 - val_accuracy: 0.9888\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0316 - accuracy: 0.9899 - val_loss: 0.0414 - val_accuracy: 0.9892\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.0411 - val_accuracy: 0.9887\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.0441 - val_accuracy: 0.9880\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.0403 - val_accuracy: 0.9895\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0396 - val_accuracy: 0.9891\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.0415 - val_accuracy: 0.9885\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.0397 - val_accuracy: 0.9886\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0394 - val_accuracy: 0.9896\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0410 - val_accuracy: 0.9887\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0409 - val_accuracy: 0.9888\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0401 - val_accuracy: 0.9893\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 64s 1ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.0393 - val_accuracy: 0.9901\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.0378 - val_accuracy: 0.9901\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0370 - val_accuracy: 0.9898\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.0380 - val_accuracy: 0.9893\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.0396 - val_accuracy: 0.9902\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0400 - val_accuracy: 0.9896\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0387 - val_accuracy: 0.9899\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0378 - val_accuracy: 0.9903\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0410 - val_accuracy: 0.9898\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.0382 - val_accuracy: 0.9898\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.0390 - val_accuracy: 0.9896\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.0390 - val_accuracy: 0.9898\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0374 - val_accuracy: 0.9907\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 63s 1ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0390 - val_accuracy: 0.9904\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0366 - val_accuracy: 0.9902\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.0384 - val_accuracy: 0.9902\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0413 - val_accuracy: 0.9898\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0402 - val_accuracy: 0.9902\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0386 - val_accuracy: 0.9902\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0384 - val_accuracy: 0.9908\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.0384 - val_accuracy: 0.9902\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0381 - val_accuracy: 0.9900\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0388 - val_accuracy: 0.9902\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0382 - val_accuracy: 0.9900\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0402 - val_accuracy: 0.9900\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.0389 - val_accuracy: 0.9908\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0381 - val_accuracy: 0.9908\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.0399 - val_accuracy: 0.9909\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0393 - val_accuracy: 0.9905\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0392 - val_accuracy: 0.9907\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0394 - val_accuracy: 0.9908\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0401 - val_accuracy: 0.9907\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0412 - val_accuracy: 0.9901\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0390 - val_accuracy: 0.9906\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0408 - val_accuracy: 0.9905\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0440 - val_accuracy: 0.9907\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 62s 1ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0424 - val_accuracy: 0.9904\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0406 - val_accuracy: 0.9910\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0398 - val_accuracy: 0.9905\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0414 - val_accuracy: 0.9908\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0407 - val_accuracy: 0.9908\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0421 - val_accuracy: 0.9902\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0411 - val_accuracy: 0.9907\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0409 - val_accuracy: 0.9909\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0427 - val_accuracy: 0.9901\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0438 - val_accuracy: 0.9900\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0445 - val_accuracy: 0.9910\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0413 - val_accuracy: 0.9911\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0456 - val_accuracy: 0.9899\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0455 - val_accuracy: 0.9908\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 60s 1ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.0444 - val_accuracy: 0.9907\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 61s 1ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0450 - val_accuracy: 0.9902\n",
      "Saved trained model at C:\\Users\\pandurand\\Documents\\Columbia\\DL\\project\\saved_models\\keras_mnist_trained_teacher.h5 \n",
      "10000/10000 [==============================] - 3s 335us/step\n",
      "Supervised learning model with 100epochs \n",
      "\n",
      "Test loss: 0.0418411054952432\n",
      "Test accuracy: 0.9904000163078308\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 200\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = False\n",
    "#num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "teacher_name = 'keras_mnist_trained_teacher.h5'\n",
    "\n",
    "# Load the data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train=x_train.reshape(x_train.shape[0],28,28,1).astype('float32')/255\n",
    "x_test=x_test.reshape(x_test.shape[0],28,28,1).astype('float32')/255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "teacher = Sequential()\n",
    "teacher.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(Conv2D(32, (3, 3)))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "teacher.add(Dropout(0.25))\n",
    "\n",
    "teacher.add(Conv2D(64, (3, 3), padding='same'))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(Conv2D(64, (3, 3)))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "teacher.add(Dropout(0.25))\n",
    "\n",
    "teacher.add(Flatten())\n",
    "teacher.add(Dense(512))\n",
    "teacher.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "teacher.add(Dense(num_classes))\n",
    "teacher.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compiling the model using RMSprop\n",
    "teacher.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#Training the model\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    teacher.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.2,\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    teacher.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_split=0.2,\n",
    "                        workers=4)\n",
    "    \n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "teacher_path = os.path.join(save_dir, teacher_name)\n",
    "teacher.save(teacher_path)\n",
    "print('Saved trained model at %s ' % teacher_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = teacher.evaluate(x_test, y_test, verbose=1)\n",
    "print('Supervised learning model with '+str(epochs)+'epochs \\n')\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we study the semi supervised learning method as described in the article, and study the impact of the ratio of true labels to pseudo labels on accuracy and loss. \n",
    "We do a loop over different ratios of label to unlabelled data (rate). And each loop does the following:\n",
    "1) Train un-noised model (teacher) on labeled data only \n",
    "2) Ten cycles of: un-noised model (teacher)->predict hard pseudolabel->training 10 epochs for noised model (student=teacher+dropout noise) on labeled+pseudo labeled->new weights. \n",
    "\n",
    "We check rates from 0.1 to 50. The student model will be the teacher model noised by a Dropout(0.5) before the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "rate=0.1:\n",
      "\n",
      "54545.454545454544\n",
      "5454.545454545456\n",
      "Original model with labelled data only predicting on test data:  0.9182000160217285\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.22905886516885365\n",
      "Test accuracy: 0.9355999827384949\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.20284845472330054\n",
      "Test accuracy: 0.9463000297546387\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.1859398955702636\n",
      "Test accuracy: 0.9534000158309937\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.17726550295493654\n",
      "Test accuracy: 0.9575999975204468\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.17548563856298752\n",
      "Test accuracy: 0.9596999883651733\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.16725050273136366\n",
      "Test accuracy: 0.9605000019073486\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.16760790004320333\n",
      "Test accuracy: 0.9635999798774719\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.17377933695675146\n",
      "Test accuracy: 0.963699996471405\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.17724166210107947\n",
      "Test accuracy: 0.9645000100135803\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.18118148278443724\n",
      "Test accuracy: 0.965499997138977\n",
      "rate=0.2:\n",
      "\n",
      "50000.0\n",
      "10000.0\n",
      "Original model with labelled data only predicting on test data:  0.9843000173568726\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.04755785420438897\n",
      "Test accuracy: 0.9865000247955322\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.04441092668661331\n",
      "Test accuracy: 0.9876999855041504\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.043048752266038624\n",
      "Test accuracy: 0.9886000156402588\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.04432162685871011\n",
      "Test accuracy: 0.9891999959945679\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.04510860146241979\n",
      "Test accuracy: 0.989300012588501\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.041244993368854344\n",
      "Test accuracy: 0.989799976348877\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.041906433611067585\n",
      "Test accuracy: 0.9901000261306763\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.04394338206744215\n",
      "Test accuracy: 0.9898999929428101\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.04926058946727209\n",
      "Test accuracy: 0.989799976348877\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.04605859905815204\n",
      "Test accuracy: 0.9902999997138977\n",
      "rate=0.3:\n",
      "\n",
      "46153.84615384615\n",
      "13846.153846153851\n",
      "Original model with labelled data only predicting on test data:  0.9922999739646912\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.02557072172381886\n",
      "Test accuracy: 0.9923999905586243\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.026000398881113506\n",
      "Test accuracy: 0.9926000237464905\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.02717542345298466\n",
      "Test accuracy: 0.9925000071525574\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.025193466057514706\n",
      "Test accuracy: 0.9929999709129333\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.02633346329165688\n",
      "Test accuracy: 0.9926000237464905\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.026790662391139496\n",
      "Test accuracy: 0.9927999973297119\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.028067585143532914\n",
      "Test accuracy: 0.9927999973297119\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.030397369305877008\n",
      "Test accuracy: 0.9932000041007996\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.031424958239584654\n",
      "Test accuracy: 0.9919999837875366\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.03114652245058121\n",
      "Test accuracy: 0.9927999973297119\n",
      "rate=0.5:\n",
      "\n",
      "40000.0\n",
      "20000.0\n",
      "Original model with labelled data only predicting on test data:  0.9919999837875366\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.021152773942575004\n",
      "Test accuracy: 0.9933000206947327\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.02045516665008063\n",
      "Test accuracy: 0.9939000010490417\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.021584435553370532\n",
      "Test accuracy: 0.9940000176429749\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.02147163870240038\n",
      "Test accuracy: 0.9934999942779541\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.022575771455085488\n",
      "Test accuracy: 0.993399977684021\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.021850210459454684\n",
      "Test accuracy: 0.9940000176429749\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.022927731728081265\n",
      "Test accuracy: 0.993399977684021\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.021592779489736584\n",
      "Test accuracy: 0.9944999814033508\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.020203156506684514\n",
      "Test accuracy: 0.9941999912261963\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.0235072251342065\n",
      "Test accuracy: 0.9939000010490417\n",
      "rate=0.75:\n",
      "\n",
      "34285.71428571428\n",
      "25714.285714285717\n",
      "Original model with labelled data only predicting on test data:  0.9937999844551086\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.01983494407404214\n",
      "Test accuracy: 0.9943000078201294\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.022596041633724234\n",
      "Test accuracy: 0.9933000206947327\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.02205735912209493\n",
      "Test accuracy: 0.9930999875068665\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.021597578871715813\n",
      "Test accuracy: 0.9940000176429749\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.026502714608982205\n",
      "Test accuracy: 0.9926999807357788\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.02392092880058335\n",
      "Test accuracy: 0.9933000206947327\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.02383981742914766\n",
      "Test accuracy: 0.9930999875068665\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.02223104796643893\n",
      "Test accuracy: 0.9929999709129333\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.023358481170632876\n",
      "Test accuracy: 0.9940000176429749\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.025921041700895875\n",
      "Test accuracy: 0.9933000206947327\n",
      "rate=1.0:\n",
      "\n",
      "30000.0\n",
      "30000.0\n",
      "Original model with labelled data only predicting on test data:  0.9930999875068665\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.02949300133511424\n",
      "Test accuracy: 0.9937999844551086\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.05283381485119462\n",
      "Test accuracy: 0.9929999709129333\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.021019959034514615\n",
      "Test accuracy: 0.9943000078201294\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.024177258320036345\n",
      "Test accuracy: 0.9937000274658203\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.02673027732153423\n",
      "Test accuracy: 0.9937000274658203\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.0534647034548223\n",
      "Test accuracy: 0.9930999875068665\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.02917153069395572\n",
      "Test accuracy: 0.9929999709129333\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.023263529054727405\n",
      "Test accuracy: 0.9939000010490417\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.02561161468308419\n",
      "Test accuracy: 0.9936000108718872\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.020180132560781203\n",
      "Test accuracy: 0.9940000176429749\n",
      "rate=2.0:\n",
      "\n",
      "20000.0\n",
      "40000.0\n",
      "Original model with labelled data only predicting on test data:  0.9934999942779541\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.02448188131758943\n",
      "Test accuracy: 0.993399977684021\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.0185711656160478\n",
      "Test accuracy: 0.9944000244140625\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.018799380464397837\n",
      "Test accuracy: 0.9940000176429749\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.025452111202385278\n",
      "Test accuracy: 0.9937999844551086\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.020334825573302805\n",
      "Test accuracy: 0.9937000274658203\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.019860249527869744\n",
      "Test accuracy: 0.9941999912261963\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.020938330800784753\n",
      "Test accuracy: 0.9943000078201294\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.023055407573789124\n",
      "Test accuracy: 0.993399977684021\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.03398309298790991\n",
      "Test accuracy: 0.9922999739646912\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.024909831408504397\n",
      "Test accuracy: 0.9933000206947327\n",
      "rate=3.0:\n",
      "\n",
      "15000.0\n",
      "45000.0\n",
      "Original model with labelled data only predicting on test data:  0.994700014591217\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.024241989097185432\n",
      "Test accuracy: 0.9945999979972839\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.018414679541205986\n",
      "Test accuracy: 0.994700014591217\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.01928755229084054\n",
      "Test accuracy: 0.9945999979972839\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.02358775779143907\n",
      "Test accuracy: 0.9941999912261963\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.026200667431857436\n",
      "Test accuracy: 0.9941999912261963\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.015967940274171998\n",
      "Test accuracy: 0.9958000183105469\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.016939616690100228\n",
      "Test accuracy: 0.9944999814033508\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.017227711182564963\n",
      "Test accuracy: 0.994700014591217\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.0203571035457775\n",
      "Test accuracy: 0.9940999746322632\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.018589663766644664\n",
      "Test accuracy: 0.9940999746322632\n",
      "rate=4.0:\n",
      "\n",
      "12000.0\n",
      "48000.0\n",
      "Original model with labelled data only predicting on test data:  0.9948999881744385\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.02283670855613891\n",
      "Test accuracy: 0.9937999844551086\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.016973818930707058\n",
      "Test accuracy: 0.9947999715805054\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.0190154507946223\n",
      "Test accuracy: 0.9944999814033508\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.018861525846802396\n",
      "Test accuracy: 0.9945999979972839\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.019169638458127157\n",
      "Test accuracy: 0.9937999844551086\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.017974098205029442\n",
      "Test accuracy: 0.9944999814033508\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.023868342255335302\n",
      "Test accuracy: 0.9947999715805054\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.020866385617130435\n",
      "Test accuracy: 0.9943000078201294\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.023016728306739242\n",
      "Test accuracy: 0.9930999875068665\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.016992215464339096\n",
      "Test accuracy: 0.9947999715805054\n",
      "rate=5.0:\n",
      "\n",
      "10000.0\n",
      "50000.0\n",
      "Original model with labelled data only predicting on test data:  0.9930999875068665\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.021542015407118014\n",
      "Test accuracy: 0.9941999912261963\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.019408590710436692\n",
      "Test accuracy: 0.9944000244140625\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.01799794949383795\n",
      "Test accuracy: 0.9948999881744385\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.018514950700992266\n",
      "Test accuracy: 0.9958000183105469\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.020892919232130224\n",
      "Test accuracy: 0.9944000244140625\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.02743247663456714\n",
      "Test accuracy: 0.9927999973297119\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.021150875953387004\n",
      "Test accuracy: 0.9944999814033508\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.019623450632876484\n",
      "Test accuracy: 0.9940999746322632\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.03926722013093531\n",
      "Test accuracy: 0.9940000176429749\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.022056483755575028\n",
      "Test accuracy: 0.9939000010490417\n",
      "rate=10.0:\n",
      "\n",
      "5454.545454545455\n",
      "54545.454545454544\n",
      "Original model with labelled data only predicting on test data:  0.9941999912261963\n",
      "x_true_pseudo.shape:  (60000, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (60000, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.018746889376332912\n",
      "Test accuracy: 0.9940999746322632\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ac1314a044e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         training=student.fit(x_true_pseudo,y_true_pseudo,validation_split=0.2,\n\u001b[1;32m--> 148\u001b[1;33m                              epochs=10,batch_size=200,verbose=0)\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[1;31m# Save weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mstudent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteacher_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#batch_size = 32\n",
    "num_classes = 10\n",
    "#epochs = 50\n",
    "#data_augmentation = False\n",
    "#num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "teacher_name = 'keras_mnist_trained_teacher.h5'\n",
    "\n",
    "teacher_path = os.path.join(save_dir, teacher_name)\n",
    "\n",
    "# Load the mnist data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train=x_train.reshape(x_train.shape[0],28,28,1).astype('float32')/255\n",
    "x_test=x_test.reshape(x_test.shape[0],28,28,1).astype('float32')/255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "#making un-noised teacher model\n",
    "teacher = Sequential()\n",
    "teacher.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(Conv2D(32, (3, 3)))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "teacher.add(Dropout(0.25))\n",
    "\n",
    "teacher.add(Conv2D(64, (3, 3), padding='same'))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(Conv2D(64, (3, 3)))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "teacher.add(Dropout(0.25))\n",
    "\n",
    "teacher.add(Flatten())\n",
    "teacher.add(Dense(512))\n",
    "teacher.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5)) #this will be uncommented for the noised student model\n",
    "teacher.add(Dense(num_classes))\n",
    "teacher.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile the teacher model using RMSprop\n",
    "teacher.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#noised student model\n",
    "\n",
    "student = Sequential()\n",
    "student.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "student.add(Activation('relu'))\n",
    "student.add(Conv2D(32, (3, 3)))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "student.add(Dropout(0.25))\n",
    "\n",
    "student.add(Conv2D(64, (3, 3), padding='same'))\n",
    "student.add(Activation('relu'))\n",
    "student.add(Conv2D(64, (3, 3)))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "student.add(Dropout(0.25))\n",
    "\n",
    "student.add(Flatten())\n",
    "student.add(Dense(512))\n",
    "student.add(Activation('relu'))\n",
    "student.add(Dropout(0.5))\n",
    "student.add(Dense(num_classes))\n",
    "student.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compiling the model using RMSprop\n",
    "student.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rate= n_true/n_pseudo\n",
    "rate=np.array([0.1,0.2,0.3,0.5,0.75,1,2,3,4,5,10,20,30,50])\n",
    "n_total=x_train.shape[0]\n",
    "\n",
    "# total number of train images (n_total) = number of true label images (n_true) + number of pseudo label images (n_pseudo)\n",
    "#                                        = n_pseudo(rate+1)\n",
    "# n_pseudo = n_total/(rate+1); n_true=n_total-n_pseudo\n",
    "\n",
    "#loop over rate values in order to find the optimal rate value for the self-learning semi supervised learning, \n",
    "#ie one that will maximize accuracy\n",
    "for r in rate:\n",
    "    print(\"rate=\"+str(r)+\":\\n\")\n",
    "    n_pseudo=n_total/(1+r)\n",
    "    n_true=n_total-n_pseudo\n",
    "    print(n_pseudo)\n",
    "    print(n_true)\n",
    "    mask_true=np.random.choice(int(n_total),int(n_true),replace=False) #generating n_true integers between 0 and n_total-1\n",
    "    mask_pseudo=[item for item in range(n_total) if item not in mask_true] #all the other numbers between 0 and n_total-1 which are not in mask_true\n",
    "    mask_pseudo=np.array(mask_pseudo)\n",
    "    x_true=x_train[mask_true[:]] #x for the labeled data\n",
    "    y_true=y_train[mask_true[:]] #y for the labeled data\n",
    "    x_pseudo=x_train[mask_pseudo[:]] #x for the unlabeled data (pseudo)\n",
    "    #training teacher model on labeled data with validation split of 0.2\n",
    "    training=teacher.fit(x_true,y_true,validation_split=0.2,\n",
    "                            epochs=10,batch_size=200,verbose=0)\n",
    "    #evaluating teacher model on test data    \n",
    "    scores=teacher.evaluate(x_test,y_test,verbose=0)\n",
    "    print(\"Original model with labelled data only predicting on test data: \",scores[1])\n",
    "\n",
    "    x_true_pseudo=np.concatenate([x_true,x_pseudo]) #concatenating x for labeled and unlabeled data\n",
    "    print('x_true_pseudo.shape: ',x_true_pseudo.shape)\n",
    "    prediction=teacher.predict_classes(x_pseudo) #predicting labels on unlabeled data\n",
    "    y_pseudo=keras.utils.to_categorical(prediction, num_classes)\n",
    "    y_true_pseudo=np.concatenate([y_true,y_pseudo]) #concatenating y for labeled and pseudo labeled\n",
    "    print('y_true_pseudo.shape: ', y_true_pseudo.shape)\n",
    "    for i in range(10): \n",
    "        # 10 loops of 10 epochs of noised student training for labeled and pseudo labeled data (step 3 in article)\n",
    "        # followed by generating predictions on unlabeled data with the teacher model (=un-noised student)\n",
    "        # which uses the weights of the trained noised student (noise does not change the weights structure of models) (step 2 in article)\n",
    "        print(i)\n",
    "        training=student.fit(x_true_pseudo,y_true_pseudo,validation_split=0.2,\n",
    "                             epochs=10,batch_size=200,verbose=0)\n",
    "        # Save weights\n",
    "        student.save_weights(teacher_path)\n",
    "        # Load weights for teacher model (un-noised)\n",
    "        teacher.load_weights(teacher_path)\n",
    "        prediction=teacher.predict_classes(x_pseudo)\n",
    "        scores=teacher.evaluate(x_test,y_test,verbose=0) #evaluating model on test data\n",
    "        print('iteration: ',i)\n",
    "        print('Test loss:', scores[0])\n",
    "        print('Test accuracy:', scores[1])\n",
    "        y_pseudo=keras.utils.to_categorical(prediction, num_classes)\n",
    "        y_true_pseudo=np.concatenate([y_true,y_pseudo]) #new y_true_pseudo to be used in next loop\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that a ratio of labeled/unlabeled above 0.3 adds some accuracy on the full training set of MNIST. It means that having less than one third of the total training set kept as unlabeled data helps the accuracy relative to the fully supervised version. Below we will do the same experiment as above, but taking a small sample of the MNIST dataset, with only 100 images in total from the training dataset, and its accuracy calculated against the full test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(60000,)\n",
      "0: 5923\n",
      "1: 6742\n",
      "2: 5958\n",
      "3: 6131\n",
      "4: 5842\n",
      "5: 5421\n",
      "6: 5918\n",
      "7: 6265\n",
      "8: 5851\n",
      "9: 5949\n",
      "(100, 28, 28, 1)\n",
      "(100,)\n",
      "0: 10\n",
      "1: 10\n",
      "2: 10\n",
      "3: 10\n",
      "4: 10\n",
      "5: 10\n",
      "6: 10\n",
      "7: 10\n",
      "8: 10\n",
      "9: 10\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "10000/10000 [==============================] - 3s 314us/step\n",
      "Small sample of 100 training images, Supervised learning model with 10epochs \n",
      "\n",
      "Test loss: 0.4271038339511415\n",
      "Test accuracy: 0.9805999994277954\n"
     ]
    }
   ],
   "source": [
    "#supervised learning on small training dataset, testing on full testing dataset\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#batch_size = 32\n",
    "num_classes = 10\n",
    "#epochs = 50\n",
    "#data_augmentation = False\n",
    "#num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "teacher_name = 'keras_mnist_trained_teacher.h5'\n",
    "\n",
    "teacher_path = os.path.join(save_dir, teacher_name)\n",
    "\n",
    "#making un-noised teacher model\n",
    "teacher = Sequential()\n",
    "teacher.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(Conv2D(32, (3, 3)))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "teacher.add(Dropout(0.25))\n",
    "\n",
    "teacher.add(Conv2D(64, (3, 3), padding='same'))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(Conv2D(64, (3, 3)))\n",
    "teacher.add(Activation('relu'))\n",
    "teacher.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "teacher.add(Dropout(0.25))\n",
    "\n",
    "teacher.add(Flatten())\n",
    "teacher.add(Dense(512))\n",
    "teacher.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5)) #this will be uncommented for the noised student model\n",
    "teacher.add(Dense(num_classes))\n",
    "teacher.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compile the teacher model using RMSprop\n",
    "teacher.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#noised student model\n",
    "\n",
    "student = Sequential()\n",
    "student.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "student.add(Activation('relu'))\n",
    "student.add(Conv2D(32, (3, 3)))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "student.add(Dropout(0.25))\n",
    "\n",
    "student.add(Conv2D(64, (3, 3), padding='same'))\n",
    "student.add(Activation('relu'))\n",
    "student.add(Conv2D(64, (3, 3)))\n",
    "student.add(Activation('relu'))\n",
    "student.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "student.add(Dropout(0.25))\n",
    "\n",
    "student.add(Flatten())\n",
    "student.add(Dense(512))\n",
    "student.add(Activation('relu'))\n",
    "student.add(Dropout(0.5))\n",
    "student.add(Dense(num_classes))\n",
    "student.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
    "\n",
    "# Compiling the model using RMSprop\n",
    "student.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Load the mnist data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train=x_train.reshape(x_train.shape[0],28,28,1).astype('float32')/255\n",
    "x_test=x_test.reshape(x_test.shape[0],28,28,1).astype('float32')/255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(y_train.shape)\n",
    "\n",
    "#checking that classes are balanced\n",
    "\n",
    "#print(np.unique(y_train))\n",
    "#print(y_train[0:40])\n",
    "\n",
    "sample_size=100\n",
    "for i in range(10):\n",
    "    print(str(i)+\":\",sum(y_train==i))\n",
    "\n",
    "#Selecting 10 images of each class\n",
    "k=0\n",
    "x_small_train=np.zeros((sample_size,28,28,1))\n",
    "y_small_train=np.full((sample_size,),-1)\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    #print(i)\n",
    "    for j in range(10):\n",
    "        if sum(y_small_train==j)<sample_size/10:\n",
    "            if y_train[i]==j:\n",
    "                x_small_train[k,:]=x_train[i,:]\n",
    "                y_small_train[k]=y_train[i]\n",
    "                k+=1\n",
    "                break\n",
    "    #print('k=',k)\n",
    "    if k==sample_size:\n",
    "        break\n",
    "        \n",
    "#print(y_small_train[0:40])\n",
    "print(x_small_train.shape)\n",
    "print(y_small_train.shape)\n",
    "\n",
    "#verifying that there are 10 images in each class\n",
    "for i in range(10):\n",
    "    print(str(i)+\":\",sum(y_small_train==i))\n",
    "    \n",
    "# Convert class vectors to binary class matrices.\n",
    "y_small_train = keras.utils.to_categorical(y_small_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)    \n",
    "\n",
    "#train teacher model\n",
    "teacher.fit(x_small_train, y_small_train,\n",
    "            batch_size=10,\n",
    "            epochs=10,\n",
    "            validation_split=0.,\n",
    "            shuffle=True)\n",
    "\n",
    "\n",
    "# Score trained model.\n",
    "scores = teacher.evaluate(x_test, y_test, verbose=1)\n",
    "print('Small sample of 100 training images, Supervised learning model with '+str(10)+'epochs \\n')\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy result above is surprisingly good for such a small dataset. Now we keep the same labeled training set of 100 images, and add an unlabeled training set determined by the ratio and run STSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(60000,)\n",
      "0: 5923\n",
      "1: 6742\n",
      "2: 5958\n",
      "3: 6131\n",
      "4: 5842\n",
      "5: 5421\n",
      "6: 5918\n",
      "7: 6265\n",
      "8: 5851\n",
      "9: 5949\n",
      "(100, 28, 28, 1)\n",
      "(100,)\n",
      "0: 10\n",
      "1: 10\n",
      "2: 10\n",
      "3: 10\n",
      "4: 10\n",
      "5: 10\n",
      "6: 10\n",
      "7: 10\n",
      "8: 10\n",
      "9: 10\n",
      "rate=0.1:\n",
      "\n",
      "1000 100 1100\n",
      "Original model with labelled data only predicting on test data:  0.9911999702453613\n",
      "x_true_pseudo.shape:  (1100, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (1100, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.024838309279835994\n",
      "Test accuracy: 0.9932000041007996\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.024450271297374183\n",
      "Test accuracy: 0.9927999973297119\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.029390712049562718\n",
      "Test accuracy: 0.9926000237464905\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.028170187339861333\n",
      "Test accuracy: 0.9926000237464905\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.023448410414327304\n",
      "Test accuracy: 0.9936000108718872\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.024384515968289885\n",
      "Test accuracy: 0.9941999912261963\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.025380505136862866\n",
      "Test accuracy: 0.993399977684021\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.025927180740772174\n",
      "Test accuracy: 0.9940000176429749\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.023985359693129628\n",
      "Test accuracy: 0.9943000078201294\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.025266775510986272\n",
      "Test accuracy: 0.9943000078201294\n",
      "rate=0.2:\n",
      "\n",
      "500 100 600\n",
      "Original model with labelled data only predicting on test data:  0.9912999868392944\n",
      "x_true_pseudo.shape:  (600, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (600, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.03875076043217476\n",
      "Test accuracy: 0.9894000291824341\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.030453584623492465\n",
      "Test accuracy: 0.9927999973297119\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.0261340775021731\n",
      "Test accuracy: 0.9937999844551086\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.029216614340353293\n",
      "Test accuracy: 0.9936000108718872\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.020488505571939503\n",
      "Test accuracy: 0.9952999949455261\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.02669896777521673\n",
      "Test accuracy: 0.9932000041007996\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.03416096746678968\n",
      "Test accuracy: 0.9926999807357788\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.025269463699121666\n",
      "Test accuracy: 0.9940999746322632\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.04669052506428074\n",
      "Test accuracy: 0.9919999837875366\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.035901892055400855\n",
      "Test accuracy: 0.9908999800682068\n",
      "rate=0.3:\n",
      "\n",
      "333 100 433\n",
      "Original model with labelled data only predicting on test data:  0.9927999973297119\n",
      "x_true_pseudo.shape:  (433, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (433, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.03258304693624154\n",
      "Test accuracy: 0.9927999973297119\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.023216665245897\n",
      "Test accuracy: 0.9940999746322632\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.030451450172225565\n",
      "Test accuracy: 0.9926000237464905\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.04065373118750474\n",
      "Test accuracy: 0.9916999936103821\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.04382865046922998\n",
      "Test accuracy: 0.9912999868392944\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.044991188009362665\n",
      "Test accuracy: 0.9916999936103821\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.0422371229997922\n",
      "Test accuracy: 0.9932000041007996\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.032945441331787916\n",
      "Test accuracy: 0.9922999739646912\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.04617543177599892\n",
      "Test accuracy: 0.9901999831199646\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.05395771780570665\n",
      "Test accuracy: 0.989300012588501\n",
      "rate=0.5:\n",
      "\n",
      "200 100 300\n",
      "Original model with labelled data only predicting on test data:  0.9909999966621399\n",
      "x_true_pseudo.shape:  (300, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (300, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.03514618513566983\n",
      "Test accuracy: 0.9929999709129333\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.03608311013302105\n",
      "Test accuracy: 0.9914000034332275\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.05050408028877727\n",
      "Test accuracy: 0.9930999875068665\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.03154843188593411\n",
      "Test accuracy: 0.9929999709129333\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.04446878000620054\n",
      "Test accuracy: 0.9937999844551086\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.029702289071334657\n",
      "Test accuracy: 0.9930999875068665\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.032005706859342356\n",
      "Test accuracy: 0.9940000176429749\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.03178623704333416\n",
      "Test accuracy: 0.9939000010490417\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.0333129972245204\n",
      "Test accuracy: 0.9939000010490417\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.03800065915908124\n",
      "Test accuracy: 0.9936000108718872\n",
      "rate=0.75:\n",
      "\n",
      "133 100 233\n",
      "Original model with labelled data only predicting on test data:  0.9940000176429749\n",
      "x_true_pseudo.shape:  (233, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (233, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.03788068565668415\n",
      "Test accuracy: 0.994700014591217\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.04078307201798914\n",
      "Test accuracy: 0.9936000108718872\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.048836117791673614\n",
      "Test accuracy: 0.9901999831199646\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.04980502963974798\n",
      "Test accuracy: 0.9929999709129333\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.05229870029038718\n",
      "Test accuracy: 0.9912999868392944\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.03746351608719288\n",
      "Test accuracy: 0.9926999807357788\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.050828829331992995\n",
      "Test accuracy: 0.9886000156402588\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.03494482823299879\n",
      "Test accuracy: 0.993399977684021\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.0452293901152403\n",
      "Test accuracy: 0.9922999739646912\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.040734839883693794\n",
      "Test accuracy: 0.9937000274658203\n",
      "rate=1.0:\n",
      "\n",
      "100 100 200\n",
      "Original model with labelled data only predicting on test data:  0.9900000095367432\n",
      "x_true_pseudo.shape:  (200, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (200, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.03352456916770343\n",
      "Test accuracy: 0.9919000267982483\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.03835444166981444\n",
      "Test accuracy: 0.9930999875068665\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.044363150989581365\n",
      "Test accuracy: 0.9916999936103821\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.04581877519234819\n",
      "Test accuracy: 0.991599977016449\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.04893096502593517\n",
      "Test accuracy: 0.9911999702453613\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.04306975689057918\n",
      "Test accuracy: 0.9926000237464905\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.046054400202689465\n",
      "Test accuracy: 0.9919999837875366\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.07010514387887493\n",
      "Test accuracy: 0.9904999732971191\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.06630705105029722\n",
      "Test accuracy: 0.9909999966621399\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.0613571834752805\n",
      "Test accuracy: 0.9911999702453613\n",
      "rate=2.0:\n",
      "\n",
      "50 100 150\n",
      "Original model with labelled data only predicting on test data:  0.991599977016449\n",
      "x_true_pseudo.shape:  (150, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (150, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.05456790535684153\n",
      "Test accuracy: 0.9912999868392944\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.06359806384695747\n",
      "Test accuracy: 0.9918000102043152\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.06355576202750962\n",
      "Test accuracy: 0.9912999868392944\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.05648828052371191\n",
      "Test accuracy: 0.9919999837875366\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.0900006471987022\n",
      "Test accuracy: 0.9850000143051147\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.06501224130626554\n",
      "Test accuracy: 0.9879999756813049\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.049382742305993314\n",
      "Test accuracy: 0.9914000034332275\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.06514743798944493\n",
      "Test accuracy: 0.9901000261306763\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.07312267564199972\n",
      "Test accuracy: 0.9890999794006348\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.04285356111091089\n",
      "Test accuracy: 0.9919000267982483\n",
      "rate=3.0:\n",
      "\n",
      "33 100 133\n",
      "Original model with labelled data only predicting on test data:  0.9914000034332275\n",
      "x_true_pseudo.shape:  (133, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (133, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.05193180104603341\n",
      "Test accuracy: 0.9922999739646912\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.04958227716115662\n",
      "Test accuracy: 0.9912999868392944\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.06222605749339879\n",
      "Test accuracy: 0.9890999794006348\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.05247495156129655\n",
      "Test accuracy: 0.9905999898910522\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.050396695074871586\n",
      "Test accuracy: 0.9915000200271606\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.07067337573013864\n",
      "Test accuracy: 0.9879999756813049\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.0591543469984927\n",
      "Test accuracy: 0.9915000200271606\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.07437020531376119\n",
      "Test accuracy: 0.9904999732971191\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.07429630493765743\n",
      "Test accuracy: 0.9902999997138977\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.11710040689627767\n",
      "Test accuracy: 0.9894000291824341\n",
      "rate=4.0:\n",
      "\n",
      "25 100 125\n",
      "Original model with labelled data only predicting on test data:  0.9901000261306763\n",
      "x_true_pseudo.shape:  (125, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (125, 10)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0\n",
      "Test loss: 0.0680462593742767\n",
      "Test accuracy: 0.9901000261306763\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.06672358556740099\n",
      "Test accuracy: 0.9900000095367432\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.1134485397388905\n",
      "Test accuracy: 0.9897000193595886\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.14285790954044048\n",
      "Test accuracy: 0.9848999977111816\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.12335549907723048\n",
      "Test accuracy: 0.9876999855041504\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.1313646703713602\n",
      "Test accuracy: 0.9865000247955322\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.13406273119041112\n",
      "Test accuracy: 0.9866999983787537\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.16575898618696852\n",
      "Test accuracy: 0.9857000112533569\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.14278378531077518\n",
      "Test accuracy: 0.9886999726295471\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.07838338035165202\n",
      "Test accuracy: 0.9889000058174133\n",
      "rate=5.0:\n",
      "\n",
      "20 100 120\n",
      "Original model with labelled data only predicting on test data:  0.9901000261306763\n",
      "x_true_pseudo.shape:  (120, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (120, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.06234511593772693\n",
      "Test accuracy: 0.9915000200271606\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.07966714196191624\n",
      "Test accuracy: 0.9909999966621399\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.11031991027208425\n",
      "Test accuracy: 0.9886999726295471\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.08333129494068005\n",
      "Test accuracy: 0.9890000224113464\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.07553440120902469\n",
      "Test accuracy: 0.9911999702453613\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.08137765662486217\n",
      "Test accuracy: 0.989300012588501\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.08742359977148777\n",
      "Test accuracy: 0.9901000261306763\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.09183138790725932\n",
      "Test accuracy: 0.9879000186920166\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.05365457715022495\n",
      "Test accuracy: 0.9911999702453613\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.05205409583729864\n",
      "Test accuracy: 0.9919999837875366\n",
      "rate=10.0:\n",
      "\n",
      "10 100 110\n",
      "Original model with labelled data only predicting on test data:  0.9848999977111816\n",
      "x_true_pseudo.shape:  (110, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (110, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.06212712711216734\n",
      "Test accuracy: 0.991599977016449\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.05749968191739379\n",
      "Test accuracy: 0.9904000163078308\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.06090296117042286\n",
      "Test accuracy: 0.9904000163078308\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.06116149939270406\n",
      "Test accuracy: 0.9904000163078308\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.05680430244679742\n",
      "Test accuracy: 0.9912999868392944\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.09096822847232515\n",
      "Test accuracy: 0.9914000034332275\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.064328010726231\n",
      "Test accuracy: 0.9900000095367432\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.05862798929645817\n",
      "Test accuracy: 0.991100013256073\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.07283579621020216\n",
      "Test accuracy: 0.9883999824523926\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.0796091852998324\n",
      "Test accuracy: 0.9900000095367432\n",
      "rate=20.0:\n",
      "\n",
      "5 100 105\n",
      "Original model with labelled data only predicting on test data:  0.9886999726295471\n",
      "x_true_pseudo.shape:  (105, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (105, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.13613052170257642\n",
      "Test accuracy: 0.9883000254631042\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.0938885342169382\n",
      "Test accuracy: 0.9902999997138977\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.15352381424088\n",
      "Test accuracy: 0.9871000051498413\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.09033619856685379\n",
      "Test accuracy: 0.989799976348877\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.0899150862048106\n",
      "Test accuracy: 0.989799976348877\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.11150625861157987\n",
      "Test accuracy: 0.9876000285148621\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.06117391725766428\n",
      "Test accuracy: 0.9922000169754028\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.10868367601324344\n",
      "Test accuracy: 0.9911999702453613\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.08064508831906332\n",
      "Test accuracy: 0.9918000102043152\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.08529509597628089\n",
      "Test accuracy: 0.9897000193595886\n",
      "rate=30.0:\n",
      "\n",
      "3 100 103\n",
      "Original model with labelled data only predicting on test data:  0.9900000095367432\n",
      "x_true_pseudo.shape:  (103, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (103, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.06827526518937792\n",
      "Test accuracy: 0.9919000267982483\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.12562655768034667\n",
      "Test accuracy: 0.9868000149726868\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.0696017150928418\n",
      "Test accuracy: 0.9904999732971191\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.13796032259953653\n",
      "Test accuracy: 0.9854999780654907\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.07163171720168987\n",
      "Test accuracy: 0.991599977016449\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.17990036664100764\n",
      "Test accuracy: 0.984000027179718\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.13410839908399555\n",
      "Test accuracy: 0.9883000254631042\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.08523054685158868\n",
      "Test accuracy: 0.9918000102043152\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.09349410595801705\n",
      "Test accuracy: 0.9901000261306763\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.06960647026757537\n",
      "Test accuracy: 0.9918000102043152\n",
      "rate=50.0:\n",
      "\n",
      "2 100 102\n",
      "Original model with labelled data only predicting on test data:  0.9901000261306763\n",
      "x_true_pseudo.shape:  (102, 28, 28, 1)\n",
      "y_true_pseudo.shape:  (102, 10)\n",
      "0\n",
      "iteration:  0\n",
      "Test loss: 0.06968458976871084\n",
      "Test accuracy: 0.9922000169754028\n",
      "1\n",
      "iteration:  1\n",
      "Test loss: 0.07078923966330562\n",
      "Test accuracy: 0.9914000034332275\n",
      "2\n",
      "iteration:  2\n",
      "Test loss: 0.07961735069360344\n",
      "Test accuracy: 0.9908999800682068\n",
      "3\n",
      "iteration:  3\n",
      "Test loss: 0.09538026014796448\n",
      "Test accuracy: 0.9886000156402588\n",
      "4\n",
      "iteration:  4\n",
      "Test loss: 0.09121986461006065\n",
      "Test accuracy: 0.9887999892234802\n",
      "5\n",
      "iteration:  5\n",
      "Test loss: 0.0956761934229132\n",
      "Test accuracy: 0.9890999794006348\n",
      "6\n",
      "iteration:  6\n",
      "Test loss: 0.13684294521906487\n",
      "Test accuracy: 0.9865000247955322\n",
      "7\n",
      "iteration:  7\n",
      "Test loss: 0.11349110179386851\n",
      "Test accuracy: 0.9860000014305115\n",
      "8\n",
      "iteration:  8\n",
      "Test loss: 0.07177720238203057\n",
      "Test accuracy: 0.9898999929428101\n",
      "9\n",
      "iteration:  9\n",
      "Test loss: 0.14615229188587614\n",
      "Test accuracy: 0.987500011920929\n"
     ]
    }
   ],
   "source": [
    "# Varying the ratio for 100 labeled images. Rest of training dataset unlabeled with ratio determining size of total dataset.\n",
    "# Testing on full test dataset\n",
    "\n",
    "# Load the mnist data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train=x_train.reshape(x_train.shape[0],28,28,1).astype('float32')/255\n",
    "x_test=x_test.reshape(x_test.shape[0],28,28,1).astype('float32')/255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(y_train.shape)\n",
    "\n",
    "#checking that classes are balanced\n",
    "\n",
    "#print(np.unique(y_train))\n",
    "#print(y_train[0:40])\n",
    "\n",
    "sample_size=100\n",
    "for i in range(10):\n",
    "    print(str(i)+\":\",sum(y_train==i))\n",
    "\n",
    "#Selecting 10 images of each class\n",
    "k=0\n",
    "x_small_train=np.zeros((sample_size,28,28,1))\n",
    "y_small_train=np.full((sample_size,),-1)\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    #print(i)\n",
    "    for j in range(10):\n",
    "        if sum(y_small_train==j)<sample_size/10:\n",
    "            if y_train[i]==j:\n",
    "                x_small_train[k,:]=x_train[i,:]\n",
    "                y_small_train[k]=y_train[i]\n",
    "                k+=1\n",
    "                break\n",
    "    #print('k=',k)\n",
    "    if k==sample_size:\n",
    "        break\n",
    "        \n",
    "#print(y_small_train[0:40])\n",
    "print(x_small_train.shape)\n",
    "print(y_small_train.shape)\n",
    "\n",
    "#verifying that there are 10 images in each class\n",
    "for i in range(10):\n",
    "    print(str(i)+\":\",sum(y_small_train==i))\n",
    "    \n",
    "# Convert class vectors to binary class matrices.\n",
    "y_small_train = keras.utils.to_categorical(y_small_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rate= n_true/n_pseudo, n_true=sample_size\n",
    "rate=np.array([0.1,0.2,0.3,0.5,0.75,1,2,3,4,5,10,20,30,50])\n",
    "#n_total=sample_size*(1+1/rate)\n",
    "\n",
    "# total number of train images (n_total) = number of true label images (sample_size) + number of pseudo label images (n_pseudo)\n",
    "#                                        = sample_size(1/rate+1)\n",
    "# n_pseudo = sample_size/rate\n",
    "\n",
    "#loop over rate values in order to find the optimal rate value for the self-learning semi supervised learning, \n",
    "#ie one that will maximize accuracy\n",
    "for r in rate:\n",
    "    print(\"rate=\"+str(r)+\":\\n\")\n",
    "    n_pseudo=int(sample_size/r)\n",
    "    n_true=sample_size\n",
    "    n_total=n_true+n_pseudo\n",
    "    print(n_pseudo, n_true, n_total)\n",
    "    x_true=x_small_train\n",
    "    y_true=y_small_train\n",
    "    x_pseudo=x_train[500:500+n_pseudo,:] #x for the unlabeled data (pseudo)\n",
    "    #training teacher model on labeled data with validation split of 0.2\n",
    "    training=teacher.fit(x_true,y_true,validation_split=0.,\n",
    "                            epochs=10,batch_size=int(n_total/10),verbose=0)\n",
    "    #evaluating teacher model on test data    \n",
    "    scores=teacher.evaluate(x_test,y_test,verbose=0)\n",
    "    print(\"Original model with labelled data only predicting on test data: \",scores[1])\n",
    "\n",
    "    x_true_pseudo=np.concatenate([x_true,x_pseudo]) #concatenating x for labeled and unlabeled data\n",
    "    print('x_true_pseudo.shape: ',x_true_pseudo.shape)\n",
    "    prediction=teacher.predict_classes(x_pseudo) #predicting labels on unlabeled data\n",
    "    y_pseudo=keras.utils.to_categorical(prediction, num_classes)\n",
    "    y_true_pseudo=np.concatenate([y_true,y_pseudo]) #concatenating y for labeled and pseudo labeled\n",
    "    print('y_true_pseudo.shape: ', y_true_pseudo.shape)\n",
    "    for i in range(10): \n",
    "        # 10 loops of 10 epochs of noised student training for labeled and pseudo labeled data (step 3 in article)\n",
    "        # followed by generating predictions on unlabeled data with the teacher model (=un-noised student)\n",
    "        # which uses the weights of the trained noised student (noise does not change the weights structure of models) (step 2 in article)\n",
    "        print(i)\n",
    "        training=student.fit(x_true_pseudo,y_true_pseudo,validation_split=0.,\n",
    "                             epochs=10,batch_size=int(n_total/10),verbose=0)\n",
    "        # Save weights\n",
    "        student.save_weights(teacher_path)\n",
    "        # Load weights for teacher model (un-noised)\n",
    "        teacher.load_weights(teacher_path)\n",
    "        prediction=teacher.predict_classes(x_pseudo)\n",
    "        scores=teacher.evaluate(x_test,y_test,verbose=0) #evaluating model on test data\n",
    "        print('iteration: ',i)\n",
    "        print('Test loss:', scores[0])\n",
    "        print('Test accuracy:', scores[1])\n",
    "        y_pseudo=keras.utils.to_categorical(prediction, num_classes)\n",
    "        y_true_pseudo=np.concatenate([y_true,y_pseudo]) #new y_true_pseudo to be used in next loop\n",
    "        \n",
    "\n",
    "\n",
    "#from keras.utils import plot_model\n",
    "#plot_model(teacher,to_file='teacher.png')\n",
    "#plot_model(student,to_file='student.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio from 0.1 to 0.75 helps the accuracy marginally. It is just difficult to do extensive studies on MNIST as the accuracy with a simple model is already very high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydotNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading pydot-1.4.1-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\pandurand\\appdata\\local\\continuum\\anaconda3\\envs\\tf\\lib\\site-packages (from pydot) (2.4.6)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading graphviz-0.13.2-py2.py3-none-any.whl (17 kB)\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
